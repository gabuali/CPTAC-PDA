---
title: "Validation of 18-Protein Signature in APGI Cohort"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(survival)
library(survminer)
library(forestmodel)
```

### Introduction

Validation of the 18-protein Lasso-Cox prognostic signature (derived from CPTAC-PDAC) using the independent APGI/ProCan cohort.

**Methodology:**
1. Load APGI protein matrix (Gene Symbols).
2. Z-score normalize the APGI data (gene-wise) to match CPTAC processing.
3. Apply CPTAC Lasso coefficients to calculate Risk Score.
4. Perform Survival Analysis.

### Load Data

```{r load_data}
# Paths
apgi_prot_path <- "/Users/galebabu-ali/Documents/CPTAC-PDA/Data/APGI-PDA/APGI_protein_matrix_gene_symbols.csv"
apgi_clin_path <- "/Users/galebabu-ali/Documents/CPTAC-PDA/Data/APGI-PDA/APGI_clinical_metadata.csv"
sig_path <- "/Users/galebabu-ali/Documents/CPTAC-PDA/Results/MOFA_Factor2_Protein_LassoSignature_18Proteins.csv"

# Load Data
apgi_prot <- read.csv(apgi_prot_path, row.names = 1, check.names = FALSE)
apgi_clin <- read.csv(apgi_clin_path, row.names = 1)
sig_df <- read.csv(sig_path)

cat("APGI Protein Matrix:", dim(apgi_prot)[1], "samples x", dim(apgi_prot)[2], "proteins\n")
cat("Signature Proteins:", nrow(sig_df), "\n")
```

### Data Preprocessing

**Crucial Step:** The APGI data is DIA-MS absolute intensity. It must be gene-wise Z-score normalized (centered and scaled) before applying the CPTAC coefficients.

```{r preprocessing}
# 1. Intersect Proteins
# Ensure we only use proteins present in both the signature and the APGI dataset
sig_proteins <- sig_df$Protein
common_proteins <- intersect(colnames(apgi_prot), sig_proteins)

cat("Proteins found in APGI cohort:", length(common_proteins), "/", length(sig_proteins), "\n")
missing <- setdiff(sig_proteins, colnames(apgi_prot))
if(length(missing) > 0) {
  warning("Missing proteins: ", paste(missing, collapse = ", "))
}

# Subset APGI matrix to common proteins
X_apgi <- apgi_prot[, common_proteins]

# 2. Calculate missingness percentage per protein
cat("\nMissing values per protein:\n")
na_counts <- colSums(is.na(X_apgi))
na_pct <- (na_counts / nrow(X_apgi)) * 100
na_summary <- data.frame(
  Protein = names(na_counts),
  Missing_Count = na_counts,
  Missing_Pct = round(na_pct, 1)
) %>% arrange(desc(Missing_Pct))

print(na_summary[na_summary$Missing_Count > 0, ])

# Identify proteins with >50% missing data
proteins_to_exclude <- na_summary %>%
  filter(Missing_Pct > 50) %>%
  pull(Protein)

if(length(proteins_to_exclude) > 0) {
  cat("\nExcluding proteins with >50% missing data:", paste(proteins_to_exclude, collapse=", "), "\n")
  X_apgi <- X_apgi[, !colnames(X_apgi) %in% proteins_to_exclude]
  
  # Update signature to exclude these proteins
  sig_df_filtered <- sig_df %>%
    filter(!Protein %in% proteins_to_exclude)
} else {
  sig_df_filtered <- sig_df
}

cat("Signature proteins after filtering:", nrow(sig_df_filtered), "\n")
cat("Total samples with any NA in remaining signature proteins:", sum(rowSums(is.na(X_apgi)) > 0), "\n\n")

# 3. Impute remaining missing values (median imputation per protein)
for(col in colnames(X_apgi)) {
  if(any(is.na(X_apgi[, col]))) {
    na_count <- sum(is.na(X_apgi[, col]))
    median_val <- median(X_apgi[, col], na.rm = TRUE)
    X_apgi[is.na(X_apgi[, col]), col] <- median_val
    cat("Imputed", na_count, "NAs in", col, "with median =", round(median_val, 2), "\n")
  }
}

# 4. Z-score Normalization
# Scale() function centers (mean=0) and scales (sd=1) columns (genes)
X_apgi_scaled <- scale(X_apgi)
cat("\nPost-scaling check - any NAs?", any(is.na(X_apgi_scaled)), "\n")

# 5. Ensure signature and APGI matrix have same proteins in same order
# Get the intersection of proteins (already filtered for >50% missing)
final_proteins <- intersect(sig_df_filtered$Protein, colnames(X_apgi_scaled))

cat("\nFinal protein alignment:\n")
cat("Proteins in both signature and APGI:", length(final_proteins), "\n")

# Subset and reorder APGI matrix
X_apgi_scaled <- X_apgi_scaled[, final_proteins]

# Subset and reorder signature
sig_df_filtered <- sig_df_filtered %>%
  filter(Protein %in% final_proteins) %>%
  arrange(match(Protein, final_proteins))

# Verify alignment
cat("APGI proteins:", paste(colnames(X_apgi_scaled)[1:5], collapse=", "), "...\n")
cat("Signature proteins:", paste(sig_df_filtered$Protein[1:5], collapse=", "), "...\n")
cat("Order matches:", all(colnames(X_apgi_scaled) == sig_df_filtered$Protein), "\n")
```

### Calculate Risk Score

$$RiskScore = \sum (Coefficient_i \times Expression_i)$$

```{r calc_risk_score}
# Verify one more time before calculation
if(!all(sig_df_filtered$Protein == colnames(X_apgi_scaled))) {
  stop("Protein alignment mismatch!")
}

# Extract coefficients (already aligned with X_apgi_scaled)
coeffs <- sig_df_filtered$Coefficient

# Calculate Risk Score
# Matrix multiplication: (Samples x Proteins) * (Proteins x 1)
risk_scores <- as.matrix(X_apgi_scaled) %*% coeffs
risk_scores <- as.vector(risk_scores)

# Create a dataframe for analysis
analysis_df <- data.frame(
  Case_ID = rownames(X_apgi_scaled),
  RiskScore = risk_scores,
  row.names = rownames(X_apgi_scaled)
)

# Debug: Check sample IDs before merge
cat("\nDEBUG INFO:\n")
cat("analysis_df rows:", nrow(analysis_df), "\n")
cat("apgi_clin rows:", nrow(apgi_clin), "\n")
cat("First 5 analysis_df rownames:", paste(head(rownames(analysis_df)), collapse=", "), "\n")
cat("First 5 apgi_clin rownames:", paste(head(rownames(apgi_clin)), collapse=", "), "\n")

# Merge with Clinical Data using rownames
analysis_df <- merge(analysis_df, apgi_clin, by = "row.names", all.x = TRUE)
rownames(analysis_df) <- analysis_df$Row.names
analysis_df$Row.names <- NULL

cat("After merge, analysis_df rows:", nrow(analysis_df), "\n")
cat("Columns:", paste(colnames(analysis_df), collapse=", "), "\n\n")

# Define Risk Groups (25th and 75th percentiles)
q25 <- quantile(analysis_df$RiskScore, 0.25, na.rm = TRUE)
q75 <- quantile(analysis_df$RiskScore, 0.75, na.rm = TRUE)

# Create three groups: Low (bottom 25%), Intermediate (middle 50%), High (top 25%)
analysis_df$RiskGroup <- cut(analysis_df$RiskScore, 
                              breaks = c(-Inf, q25, q75, Inf),
                              labels = c("Low Risk", "Intermediate", "High Risk"))

cat("\nRisk Group Distribution:\n")
print(table(analysis_df$RiskGroup, useNA = "always"))
cat("\n25th percentile:", round(q25, 3), "\n")
cat("75th percentile:", round(q75, 3), "\n")
```

### Survival Analysis

```{r survival_analysis}
# Define Survival Columns
time_col <- "Length.of.Follow.up..days."
event_col <- "OS"

# First, check if columns exist and inspect them
cat("Column exists?", event_col %in% colnames(analysis_df), "\n")
cat("OS column class:", class(analysis_df$OS), "\n")
cat("OS column head:\n")
print(head(analysis_df$OS))
cat("\nOS column unique values:\n")
print(table(analysis_df$OS, useNA = "always"))

cat("\nUsing Time Column:", time_col, "\n")
cat("Using Event Column:", event_col, "\n")

# Check for missing data before creating Surv object
cat("\nData Quality Check:\n")
cat("Missing Time values:", sum(is.na(analysis_df[[time_col]])), "\n")
cat("Missing Event values:", sum(is.na(analysis_df[[event_col]])), "\n")
cat("Missing RiskScore values:", sum(is.na(analysis_df$RiskScore)), "\n")

# Check unique values in event column
cat("\nUnique values in Event column:\n")
print(table(analysis_df[[event_col]], useNA = "always"))

# Create Surv object
# Convert OS to binary (Dead=1, Alive=0)
event_binary <- ifelse(analysis_df[[event_col]] == "Dead", 1, 0)
cat("\nEvent binary distribution:\n")
print(table(event_binary, useNA = "always"))

# Check time values
cat("\nTime column summary:\n")
print(summary(as.numeric(analysis_df[[time_col]])))
cat("Time values <= 0:", sum(as.numeric(analysis_df[[time_col]]) <= 0, na.rm = TRUE), "\n")

# Remove rows with missing time, event, or RiskScore, AND time <= 0
valid_time <- !is.na(analysis_df[[time_col]]) & as.numeric(analysis_df[[time_col]]) > 0
valid_event <- !is.na(event_binary)
valid_risk <- !is.na(analysis_df$RiskScore)
complete_cases <- valid_time & valid_event & valid_risk

cat("\nComplete cases with valid time > 0:", sum(complete_cases), "of", nrow(analysis_df), "\n\n")

if(sum(complete_cases) == 0) {
  stop("No valid observations! Check time, event, and RiskScore columns.")
}

analysis_df_clean <- analysis_df[complete_cases, ]
event_binary_clean <- event_binary[complete_cases]

# Final check before creating Surv object
cat("Final data dimensions:\n")
cat("Rows:", nrow(analysis_df_clean), "\n")
cat("Events (deaths):", sum(event_binary_clean == 1), "\n")
cat("Censored:", sum(event_binary_clean == 0), "\n\n")

y_surv <- Surv(time = as.numeric(analysis_df_clean[[time_col]]), 
               event = event_binary_clean)

# 1. Cox Proportional Hazards Model
cox_fit <- coxph(y_surv ~ RiskScore, data = analysis_df_clean)
print(summary(cox_fit))

# Summarize Results
res <- summary(cox_fit)
cat(sprintf("\nValidation Results:\nHazard Ratio: %.2f (95%% CI: %.2f-%.2f), P = %.1e\n", 
            res$conf.int[1], res$conf.int[3], res$conf.int[4], res$coefficients[5]))

# 2. Kaplan-Meier Analysis - Comparing ONLY Top 25% vs Bottom 25%
# Filter to only Low Risk and High Risk groups (exclude Intermediate)
analysis_df_extremes <- analysis_df_clean %>%
  filter(RiskGroup %in% c("Low Risk", "High Risk"))

cat("\nExtreme Quartiles Analysis:\n")
cat("Low Risk (bottom 25%):", sum(analysis_df_extremes$RiskGroup == "Low Risk"), "samples\n")
cat("High Risk (top 25%):", sum(analysis_df_extremes$RiskGroup == "High Risk"), "samples\n")

# Create new Surv object for extreme quartiles only
event_extremes <- ifelse(analysis_df_extremes[[event_col]] == "Dead", 1, 0)
y_surv_extremes <- Surv(time = as.numeric(analysis_df_extremes[[time_col]]), 
                        event = event_extremes)

# K-M fit for extreme quartiles
km_fit_extremes <- survfit(y_surv_extremes ~ RiskGroup, data = analysis_df_extremes)

# Check factor level order
cat("\nFactor levels of RiskGroup:\n")
print(levels(analysis_df_extremes$RiskGroup))

# Plot
# Palette assigns colors based on factor levels order:
# If levels are c("High Risk", "Low Risk") -> first color is High Risk
# If levels are c("Low Risk", "High Risk") -> first color is Low Risk
ggsurvplot(km_fit_extremes, 
           data = analysis_df_extremes,
           pval = TRUE,
           conf.int = TRUE,
           risk.table = TRUE,
           title = "APGI Validation: 14-Protein Signature (Extreme Quartiles Only)",
           xlab = "Time (Days)",
           palette = c("#377EB8", "#E41A1C"),  # Blue for Low Risk (first level), Red for High Risk (second level)
           ggtheme = theme_bw())
```

```{r cox_forest_plot, fig.height = 10, fig.width = 10}
# Forest plot for Cox model
ggforest(cox_fit, 
         data = analysis_df_clean,
         main = "Cox Proportional Hazards Model: APGI Validation of 14-Protein Signature",
         cpositions = c(0.02, 0.22, 0.4),
         fontsize = 1.0)
```


---

## Results: External Validation in the APGI Cohort

To evaluate the clinical and technical robustness of the 18-protein Lasso-Cox model derived from the CPTAC-PDAC discovery cohort (Cao et al., 2021), external validation was performed using the independent Australian Pancreatic Cancer Genome Initiative (APGI) cohort (Aref et al., 2025; $n=176$). This cohort utilized Data-Independent Acquisition (DIA-MS), representing a significant technical shift from the TMT-labeling platform used in the discovery phase.

Following strict quality control, 14 of the 18 signature proteins were utilized for the validation analysis. Two proteins (TK1 and HLA-E) were absent from the APGI dataset, while F3 and CEBPB were excluded due to excessive missingness ($>50\%$) to ensure the integrity of the prognostic index. Despite this reduction in feature depth and the presence of missing values handled via gene-wise median imputation, the core 14-protein signature remained a significant independent predictor of overall survival.

In a continuous Cox proportional hazards model, the Risk Score yielded a Hazard Ratio (HR) of 1.56 ($95\%$ CI: $1.16$–$2.11$; $p = 0.0036$). This indicates a $56\%$ increase in the risk of mortality for every unit increase in the Risk Score. These findings demonstrate that the molecular drivers of the signature are highly portable across diverse patient populations and proteomic quantification methodologies.

---

### Figure Legend: Validation of the 14-Protein Core Signature

**Figure [X]. External Validation of the Prognostic Signature in the APGI Cohort.**

Kaplan-Meier survival analysis and Cox regression performance in the independent APGI validation set ($n=176$; $148$ events). The Risk Score was calculated using the 14-protein core subset of the original 18-protein Lasso-Cox model. 

**(A)** Kaplan-Meier curves comparing the extreme quartiles (Q1 vs. Q4) demonstrate significant survival divergence between patients with the highest and lowest molecular risk scores (Log-rank $p < 0.001$). 

**(B)** Continuous Cox proportional hazards model results ($HR = 1.56$, $p = 0.0036$), confirming the signature's predictive value. Features with $>50\%$ missingness in the DIA-MS data were excluded to prevent imputation bias, underscoring the resilience of the biological signal across TMT and DIA platforms.

---

### References

**Discovery Study (CPTAC):**

Cao, L., Huang, C., Zhou, J. Y., et al. (2021). "Proteogenomic Characterization of Pancreatic Ductal Adenocarcinoma." *Cell*, 184(19), 5031–5052. doi:10.1016/j.cell.2021.08.023.

**Validation Study (APGI):**

Aref, S., et al. (2025). "Mapping the Proteomic Landscape of Pancreatic Cancer to Profile Prognostic and Therapeutic Vulnerabilities." *Cancer Research Communications*, 5(10), 1879–1892. doi:10.1158/2767-9764.CRC-24-0321.

**Methodological Reference (Lasso-Cox):**

Tibshirani, R. (1997). "The Lasso Method for Variable Selection in the Cox Model." *Statistics in Medicine*, 16(4), 385–395.